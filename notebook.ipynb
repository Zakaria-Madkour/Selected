{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import soundfile as sf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation\n",
    "### Download data of <a href=\"https://huggingface.co/datasets/google/fleurs/tree/main/data/en_us\">English</a>, <a href=\"https://huggingface.co/datasets/google/fleurs/tree/main/data/ar_eg\">Arabic</a>, and <a href=\"https://huggingface.co/datasets/google/fleurs/tree/main/data/de_de\">German</a> languages from <a href=\"https://huggingface.co/datasets/google/fleurs\">Fleurs</a> dataset and save them locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./data\"): \n",
    "    data_folder_paths = [\"ar_eg\", \"en_us\", \"de_de\"]\n",
    "    for data_folder in data_folder_paths:\n",
    "        # Specify the path where you want to download the folder contents\n",
    "        download_path = \"./data/\" + data_folder +\"/\"\n",
    "        # Load the dataset\n",
    "        dataset = load_dataset(\"google/fleurs\", data_folder)\n",
    "        dataset.save_to_disk(download_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the downloaded datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_dataset = load_from_disk(\"./data/en_us/\")\n",
    "arb_dataset = load_from_disk(\"./data/ar_eg/\")\n",
    "ger_dataset = load_from_disk(\"./data/de_de/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# 1. filter the datasets by taking sound files with the same length\n",
    "# 2. get mel spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
      "        num_rows: 2602\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
      "        num_rows: 394\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
      "        num_rows: 647\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'path': '10004088536354799741.wav',\n",
       " 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -3.15904617e-06, -3.03983688e-06, -3.27825546e-06]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(eng_dataset)\n",
    "eng_dataset[\"train\"][0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_wav(path, file_name, audio_data, sampling_rate):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    # Save the audio data as a WAV file\n",
    "    sf.write(path+file_name, audio_data, sampling_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_wav(\"./eng/\",\"eng1.wav\", eng_dataset[\"train\"][0][\"audio\"][\"array\"], eng_dataset[\"train\"][0][\"audio\"][\"sampling_rate\"])\n",
    "generate_wav(\"./ger/\",\"ger1.wav\", ger_dataset[\"train\"][0][\"audio\"][\"array\"], ger_dataset[\"train\"][0][\"audio\"][\"sampling_rate\"])\n",
    "generate_wav(\"./arb/\",\"arb1.wav\", arb_dataset[\"train\"][0][\"audio\"][\"array\"], arb_dataset[\"train\"][0][\"audio\"][\"sampling_rate\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
